\begin{abstract}

    This thesis explores the concept of automatic music transcription.
    A literature review is conducted to provide a concise overview of the
    subject, including state-of-the-art methods and how they can be used to
    better improve user satisfaction of current systems.

    This thesis explores the method known as non-negative matrix factorization
    as applied to time-frequency representations of audio signals. The primary
    concept that will be reviewed to aid with understanding this technique is
    the Short-Time Fourier Transform.

    A secondary avenue of exploration is machine learning algorithms and their
    application to automatic music transcription systems. A preliminary review
    is provided to prepare the reader for the related discussions and insights
    uncovered in this investigation.

    The design and application of a monophonic non-negative matrix factorization
    model and a polyphonic neural network model are presented followed by a
    discussion of the results. Thereafter, a discussion is presented on how
    higher level musical knowledge can be incorporated into future models to
    improve their accuracy.

    The monophonic model was tested on a recording of a chromatic scale played
    on piano and achieved an accuracy of 100\%. This model had fast
    implementation, but needs appropriate tuning dependent on contextual
    factors.

    The polyphonic model achieved an f-measure of 75\% making use of a
    weighted binary entropy loss function tested on music samples from the
    MusicNet database.

\end{abstract}
