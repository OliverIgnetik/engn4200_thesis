\SetPicSubDir{ch-Intro}

\chapter{Introduction}
\vspace{2em}

\section{What is Automatic transcription ?}
The nature of music signals, which often contain several sound sources that are
highly correlated over both time and frequency, means that Automatic Music
Transcription (AMT) is still considered an open problem in the literature.
Usually an AMT system takes an audio waveform as input, computes a
time-frequency representation and outputs pitches over time or ideally a typeset
music score. Most approaches are designed to achieve an intermediate goal in AMT
which does not actually resemble musical notation as shown in
\autoref{intro:fig:AMT-process}.

The capability of transcribing music audio into music notation is a fascinating
example of human intelligence. It involves analyzing complex
auditory scenes, recognizing musical objects, forming musical structures and
checking alternative hypotheses. AMT refers to the design of computational
algorithms to convert acoustic music signals into some form of music notation.
It is a challenging task and considered an unsolved problem in signal processing and
artificial intelligence. This problem is particularly challenging in polyphonic
music were even the most advanced systems are far behind meeting the accuracy of
trained musicians. \cite{spma2011:Klapuri}

% It comprises several subtasks, including multipitch estimation (MPE), onset
% and offset detection, instrument recognition, beat and rhythm tracking,
% interpretation of expressive timing and dynamics and score typesetting. See
% \autoref{ch:system} for a graphical representation of the sub systems that
% make up typical AMT systems. \cite{amt2019:Benetos}

\begin{figure}[!b]
    \centering
    \includegraphics[width=.6\linewidth]{\Pic{jpg}{AMT-process}}
    \caption{AMT process figure taken from NUS ISMIR 2019 tutorial \cite{ISMIR-tut:Benetos} }
    \label{intro:fig:AMT-process}
\end{figure}

\section{Key Challenges}

Despite significant progress in AMT research, there exists no end-user application that
can accurately and realiably transcribe music containing the range of instrument combinations and
genres found in recorded music.

There are several factors that make AMT particularly challenging :

\begin{enumerate}
    \item \emph{Polyphonic mixtures} - inferring musical attributes from a signal containing
          multiple simultaneous sources with different pitch, loudness and sound quality is extremely difficult. Even the
          task of disentangling the harmonics of two coinciding pitches is not trivial. For consonant intervals, which are often
          seen in diatonic harmonies and form basic harmonic buidling blocks, the notes share many of the same harmonics making the
          seperation of voices even more difficult. \cite{ISMIR-tut:Benetos}
    \item \emph{Synchronous sound sources} - musicians pay close attention to metrical structure and rhythmic synchronicity,
          which violates statistical independence between sources which is often used in Automatic Speech Recognition to facilitate seperation.
    \item \emph{Lack of ground-truth transcriptions} - the annotation of polyphonic music
          is extremely time consuming and requires high expertise especially in symphonic pieces were there
          are many concurrent sound events. Even when there is sheet music available for a particular piece, they
          are difficult to align with an audio signal. Sheet music at best is considered as a weak label due to the fact
          subjective interpretation often plays a role. This is true even in the most prudent genres like classical music were musicians strive to pertain to the
          score as much as possible. \cite{ground-truths:Su}
\end{enumerate}

\section{Commercial Applications}

A successful AMT system would enable a broad range of interactions between
people and music, including automatic instrument tutoring, dictating improvised
musical ideas and automatic music accompaniment, music content visualization and
intelligent content-based editing, indexing and recommendation of music and
analyzing jazz improvisations and other nonannotated music. Given the potential
applications, the problem has attracted commerical interest and a number of AMT
software exists. \cite{amtfc2013:Benetos}

Commercially available applications include Melodyne (\url{http://www.celemony.com/en/melodyne }), Transcribe!(\url{https://www.seventhstring.com/xscribe/ })  and AudioScore exist.
In context-specific transcription scenarios these applications can reach multipitch detection accuracies of 90\% or more. Even some open source
academically produced applications can reach similar performance levels. \cite{context-dependent2016:Cogliati}
However, given complex ensemble pieces with multiple instruments the performance of such systems
is still far behind that of a trained musician.

\section{Overview}

\subsection{Research Question}

Can incorporating higher level musical knowledge into existing AMT systems
improve the perceived quality of the output for human listeners ?

\subsection{Project Scope}

The scope of the thesis will focused on western music with its associated modes
and scales. This paper will be restricted to approaches that analyze music
produced by pitched instruments such as pianos and guitars. Outside of the scope
of the paper will be methods for transcribing percussive instruments such as
drums.

\section{Thesis Synopsis}

\autoref{ch:review} serves as a review of important musical concepts and a
literature review in music signal processing. Crucial Digital Signal Processing
(DSP) techniques are relations are presented. Finally a number of state of the
art methods and their characteristics are explored.

\autoref{ch:system} provides details on the system architecture of the AMT
systems used in this research project. \autoref{ch:results} presents the crucial
results of this research paper and discusses their implications.
\autoref{ch:concl} discusses the outcomes of the thesis and explores directions
for future research.

\section{Resources}

\begin{enumerate}
    \item Core Python Libraries - see
          \href{https://github.com/OliverIgnetik/engn4200_thesis}{github repo}
          for thesis.yaml file for all dependencies
          \begin{enumerate}
              \item LibROSA - LibROSA is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems.\newline \url{https://librosa.github.io/librosa/}
              \item mir\_eval -  Python library for computing common heuristic accuracy scores for various music/audio information retrieval/signal processing tasks. \newline \url{https://pypi.org/project/mir_eval/}
          \end{enumerate}
    \item Datasets
          \begin{enumerate}
              \item MAPS - A piano database for multipitch estimation and automatic
                    transcription of music \cite{MAPS:Emiya}
              \item MusicNet - A curated collection of labeled classical music \cite{thickstun2018invariances}
              \item MAESTRO - MIDI and Audio Edited for Synchronous TRacks and
                    Organization \cite{hawthorne2018enabling}
          \end{enumerate}

    \item Work Environment
          \begin{enumerate}
              \item Anaconda Package Manager
              \item Jupyter Lab NoteBooks
          \end{enumerate}
\end{enumerate}
