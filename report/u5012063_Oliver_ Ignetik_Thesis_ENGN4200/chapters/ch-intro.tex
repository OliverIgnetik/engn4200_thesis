\SetPicSubDir{ch-Intro}

\chapter{Introduction}
\vspace{2em}

The capability of transcribing music audio into music notation is a fascinating
example of human intelligence. It involves perception (analyzing complex
auditory scenes), cognition (recognizing musical objects), knowledge
representation (forming musical structures), and inference (testing alternative
hypotheses). Automatic music transcription (AMT), i.e., the design of
computational algorithms to convert acoustic music signals into some form of
music notation, is a challenging task in signal processing and artificial
intelligence. It comprises several subtasks, including multipitch estimation
(MPE), onset and offset detection, instrument recognition, beat and rhythm
tracking, interpretation of expressive timing and dynamics and score
typesetting.
\cite{amt2019:Benetos}

The ultimate goal of and AMT system is to transform and audio signal into a
sheet music representation which can be readily understood by a musician trained
in sight reading. This process is shown in \autoref{intro:fig:AMT-process} which
illustrates the MIDI piano roll representation. Given the task is considered so
difficult it is not uncommon to map the audio signal to an intermediary domain
that does not yet indicate high level musical structures such as time signature
and key.

\begin{figure}[!b]
    \centering
    \includegraphics[width=.6\linewidth]{\Pic{jpg}{AMT-process}}
    \caption{AMT process figure taken from NUS ISMIR 2019 tutorial \cite{ISMIR-tut:Benetos} }
    \label{intro:fig:AMT-process}
\end{figure}


Many techniques in recent times have be focused around finding the onset time
and frequency content of the sound event in question. These approaches have been
shown to be highly effective for individual instruments. As such some commercial
transcription systems such as Melodyne, Transcribe! and AudioScore exist.
However, given complex ensemble pieces with multiple instruments the performance
of these systems is no longer considered acceptable.

A successful AMT system would enable a broad range of interactions between
people and music, including music education (e.g., through systems for automatic
instrument tutoring), music creation (e.g., dictating improvised musical ideas
and automatic music accompaniment), music production (e.g., music content
visualization and intelligent content-based editing), music search (e.g.,
indexing and recommendation of music by melody, bass,rhythm, or chord
progression), and musicology (e.g., analyzing jazz improvisations and other
nonannotated music).As such, AMT is an enabling technology with clear potential
for both economic and societal impact. \cite{amtfc2013:Benetos}

\section{Overview}

\subsection{Research Question}

Can incorporating higher level musical knowledge into existing AMT systems
improve the perceived quality of the output for human listeners ?

\subsection{Project Scope}

\lipsum[1]

\section{Thesis Synopsis}

The rest of this thesis is organized as follows. In \autoref{ch:review}, we
conduct a literature review. We will review crucial Digital Signal Processing
(DSP) techniques and expand upon these with methods unique to music DSP. Finally
we will investigate relevant state of the art methods in music DSP.

\autoref{ch:system} provides details on the system architecture of the AMT
systems used in this research project. \autoref{ch:results} . We conclude the
entire thesis as well as discuss further directions for future research in
\autoref{ch:concl}.

\section{Resources}

You may go to \href{https://github.com/OliverIgnetik/engn4200_thesis}{my GitHub
    repository} or access the url
\url{https://github.com/OliverIgnetik/engn4200_thesis} directly.
