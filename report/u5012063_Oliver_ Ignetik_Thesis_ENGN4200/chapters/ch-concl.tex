\SetPicSubDir{ch-Conclusion}
\chapter{Conclusion}
\label{ch:concl}

\section{Future Research Directions}

Despite significant progress in the field of AMT as can be seen by inspecting
the MIREX results \cite{MIREX} of recent years. The performance of even the most
recent systems falls well below that of a human expert particularly in symphonic
music where this is many simultaneous instruments. \cite{roadmap-MIR:Serra2013}

\subsection{User Informed Transcription}

The fact that current AMT systems do not reach the same level of precision in
extracting information from music audio signals as trained musicians do,
suggests that a human in the loop system whereby the user provides input to the
system to attain satisfactory results.

Humans are extremely good at instrument identification, note onset detection,
and segregation. While computers are capable of performing operations quickly on
extremely large datasets. \cite{ISMIR-tut:Benetos} \emph{Semi automatic
    approaches} may be able to to obtain results faster then human transcription and
more accurate then fully automatic approaches. \cite{ISMIR-tut:Benetos}

Tha main effort in this research avenue should be to the type of input that
users can provide which is most beneficial to the system and how to incorporate
high level abstract musical concepts.

One approach which incorporates user feedback requires the indentification of
the type of instrument and scale or notes used. \cite{user-inform:Kirchoff2012}
The technique used in this approach performed considerably better then a fully
automatic approach using the same type of algorithm. Another approach required
the user to hum the melody which was used to help extract it from the mixture
signal. \cite{humming2009:Smaragdis}

\subsection{Score Informed Transcription}

The musical score of a piece can provide invaluable information for AMT systems
to exploit. In certain situations, take for example classical performances, a
method known as score-to-audio alignment can be used. \cite{Wang2017} Automatic
music tutoring applications are becoming more popular in recent years with the
advent of such programs as Fender Play, Yousician and more taking advantage of
this idea. In the use cases correctly played passages need to be identified
along with mistakes made by the student. However, these applications are based
around correcting local mistakes in pieces and do not correct major changes in
performances such as the form of a piece.  Finally, the more challenging problem
of lead-sheet informed transcription is almost unexplored with no notable
published papers at this time. A lead sheet can be thought of as a blueprint to
an improvisor indicating only the melody and harmonic progression. These are
very weak labels and make incorporating the information they provide extremely
difficult. To conclude while this problem has been explored for certain
instruments such as the piano there are many other instruments still yet
unexplored and the task of lead-sheet informed transcription remains unexplored.

\subsection{Context specific transcription}

The ultimate goal of a complete multi-instrument AMT system without specific
knowledge of any contextual parameters such as instrumentation or recording
conditions is not yet achievable. However, considerable progress has been made
by incorporating contextual parameters into existing pitch detection algorithms.
For example multipitch detection accuracy in context-specific piano
transcription can now exceed 90\%. \cite{context-dependent2016:Cogliati}

Most transcription algorithms that are based on heuristic procedures even
deliberately disregard specific timbral characteristics in order to enable
independence of instrumentation in pitch detection. Even those transcription
methods that are tested on specific datasets are not tailored to that particular
instrument.

Transcription systems typically model a wide range of instruments employing a
single set of algorithms, assuming that it can be applied equally well to
different kinds of instruments and situations. The NMF approach presented in
this paper had no information about instrument-specific harmonic profiles
incorporated into the model. Depending on the sound production mechanism of
instruments, the the characteristics of the harmonics require the introduction
of instrument specific parameters in the common models used. For example the
spectral characteristics of a note produced on a violin are quite different to
those produced on a piano.

\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{\Pic{png}{violin-vs-piano}}
    \caption{Middle C (262 Hz) played on a piano and a violin. The top pane
        shows the waveform, with the spectrogram below. Zoomed-in regions shown
        above the waveform reveal the 3.8-ms fundamental period of both notes
        \cite{spma2011:Klapuri}}
    \label{conc:fig:violin-vs-piano}
\end{figure}

\subsection{Evaluation Metrics}

Some notes are more musically important than others and as such some errors are
more noticable to human listeners then others. For example, in certain genres
like pop music, wrong notes within the scale are less noticable then those from
notes outside the scale with alot of tension. Most AMT approaches are evaluated
using the set of metrics proposed for the MIREX Mutliple-F0 Estimation and Note
Tracking public evaluation tasks.  While the metrics do provide insight into
building successful AMT systems they do not correspond with human perception of
transcription accuracy. Take for example, a repeated missed note compared to a
repeating jumping octave or a note in a completely different register. Some
ideas that have been proposed include observing how music teachers grade music
dictation exams and better understanding the cognitive processes behind
processing music in humans. \cite{MIR-recent-dev:Schedl}

\subsection{Music Language Models (MLMs)}

AMT systems can model both the acoustic sequences and the underlying notes over
time. It provides the main link between music signal processing and symbolic
music processing. Some approaches have attempted to incorporate what are known
as Music Language Models to better improve the transcription accuracy. These
models attempt to encode higher level musical structures such as metric
signature, scales and chords and key signature. Key is a high-level musical cue
that provides useful information prior to transcription about the combination of
potential notes and chords. This can be achieved by giving more wieght to
predictions made within the same key. Furthermore, musicological models could be
used to describe longer-term relationships in audio recordings such as song
structure and modulations between keys. This alludes to the fact that most
existing AMT systems are data driven and often the errors they make are not
musically meaningful. In the analogous field of Speech Recognition acoustic and
language models are applied with great success. However these models can not be
directly applied to AMT systems because :
\begin{itemize}
    \item Music is polyphonic
    \item Music rhythm involves much longer temporal dependencies
    \item Music harmony arrangement involves rich music theory \end{itemize}1

Some of the most promising applications of these ideas made use of Recurrent
Neural Networks which can better model long term dependencies in time. These
approaches were noted to achieved 10\% improvements in frame-level transcription
accuracy with respect to similar models that did make use of MLS. Further work
is needed to better encode high level musical structures into current systems.
\cite{amt-note-to-audio:Lewandowski,end-to-end-nn-2016:Sigtia}

\subsection{Parameters for NNs}
There needs to be substantial work in discovering appropriate loss functions to
be used in optimization of NN models. The choice of loss function is directly
related to the activation function used in the output layer of the NN. This
paper showed that despite treating an AMT problem as multi-label probelm with a
softmax activation function on the output layer binary crossentropy was not a
suitable loss function to be used in optimizing the model. This was shown to be
related to the class imbalance between inactive and active notes in each frame.
In recent times investigations in to recurrent neural networks have shown the
most promise as they are believed to be modelling long term interdependencies in
between notes which may be improving model performance by capturing harmonic
relations in the deeper layers of the network.
\cite{end-to-end-nn-2016:Sigtia,amt-note-to-audio:Lewandowski}


\section{Conclusion}
There are several issues in the AMT problem and if these are not addressed the
performance of current systems will never be sufficient for certain
applications. This paper has reviewed the current state of AMT research in
certain key areas and identified major challenges and outlined promising
directions for future work.

A potential way forward in the field is to make use of more information in the
form of incorporating high-level musical conventions, instrumental
characteristics or explicit user input to resolve ambiguties. In
\autoref{section:challenges} it was discussed how context, whether that be
instrumentation or score information, can be used to inform high-level models
that are more powerful then generalized models as they can encode important
information about key, instrument identities and metrical structure that can
inform the pitch detection algorithms.

To potentiate progress in these research avenues, expertise from several
disciplines will be needed such as audio engineering, musicology and acoustics.
Furthermore there needs to be a greater emphasis on incorporation of end-user
applications that provide crucial feedback on how musicians interact with AMT
systems and what are the most salient features in music recordings.

The work outlined in this paper illustrates key approaches and techniques that
have been developed in the rapidly evolving field of music signal analysis, but
as discussed there is much room for improvement and for new inventions and
discoveries, leading to more powerful and innovative applications. For the
moment, human listeners remain far superior to machines in interpreting
information in music signals. However, by addressing the major challenges
presented this gap will be greatly reduced by unlocking the full potential of
music signal processing techniques.

% \vspace{2em}
